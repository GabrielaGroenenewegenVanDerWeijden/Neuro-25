{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "y6ZjeZZb1ACV"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielaGroenenewegenVanDerWeijden/Neuro-25/blob/main/Decoding_Horizontal_Eye_Position.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is a (python) notebook.\n",
        "To be able to use it, go through this:\n",
        "\n",
        "\n",
        "1. in the file menu (top left), click ```open in playground```\n",
        "3. still in the file menu, click ```save copy in drive```, to make your own personalized and editable copy of this file.\n",
        "4. edit as you like. If something breaks irreparably, go back to step 1.\n",
        "\n",
        "More information about jupyter notebooks and colab is here:\n",
        "\n",
        "0. Learn about how to use google colaboratory [video](https://www.google.com/search?client=opera&q=introduction+to+google+colab&sourceid=opera&ie=UTF-8&oe=UTF-8#kpvalbx=_gYFDX5-jEcv0kwWY_YGgCg113)\n",
        "1. Have a look at this [example notebook](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb) that introduces python and colab."
      ],
      "metadata": {
        "id": "9SkJDNRemMc8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImczRANuXV3c"
      },
      "source": [
        "# How to use this tutorial:\n",
        "\n",
        "You are expected to read this document sequentially, and answer questions you will find in the comments and at the bottom of the document. You will present your answers at our next encounter.\n",
        "\n",
        "> To edit and to run, go to the menu `File> Save a Copy in Drive` or `File > Open in Playground Mode`\n",
        "\n",
        "*Tip: open the table of contents, on the icons on the top-right corner menu bar (look like bullet points).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcf9BzdGjizf"
      },
      "source": [
        "# Tutorial: Representing Eye Position in Populations of Spiking Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHTW0oDDjpjw"
      },
      "source": [
        "In this [colab](https://colab.research.google.com/notebooks/intro.ipynb) we will use the simulator [NENGO](www.nengo.ai) to implement a neural population of leaky integrate and fire neurons that represents eye position (a continuous variable). This is an ultra simple example for you to **get a sense of what it means for populations of neurons to encode physical quantities**.\n",
        "\n",
        "We will **create a population of encoding neurons**, which effectively will be basis functions, and will respond monotonically but non-linearly.\n",
        "\n",
        "The response of these LIF neurons are derived from response properties found  in the NPH and MVN, which have tuning curves for specific eye positions.\n",
        "\n",
        "We will then **decode the eye position information** from the population of neurons. We will then verify the quality of the decoding and observe how it changes with the size of the neural population and other biophysical properties of the modeled neurons such as membrane time constant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STNe4I_hl2IL"
      },
      "source": [
        "## Learning Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0MCkNmJl5e2"
      },
      "source": [
        "- Learn how to implement a LIF network in Nengo\n",
        "- Probe and display network inputs and outputs\n",
        "- Encode an input quantity in a LIF population\n",
        "- Decode the quantity from these LIF neurons\n",
        "- Change properties of Networks, LIF neurons and synapses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgFFQmu9jX1l"
      },
      "source": [
        "For reference code snippets check: https://www.nengo.ai/nengo/examples/advanced/nef-summary.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGJRtXPONr1x"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWD81kHONtx-"
      },
      "source": [
        "- [Basic knowledge about integrate and fire neurons](https://lcnwww.epfl.ch/gerstner/SPNM/node26.html)\n",
        "  - membrane time constant\n",
        "  - response function\n",
        "- Useful but not essential: [Basic notions of object oriented programming](https://www.youtube.com/watch?v=pTB0EiLXUC8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDmF_cDmhZyV"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- Nengo uses optimal linear decoding to find weights that reconstruct a signal from neuronal activity. [Here is a video I recorded with the analytical derivation of how to find the optimal decoding weights](https://youtu.be/A8Mc_IsVSTE)\n",
        "- [A nice set of applets to get a sense of models of spiking](http://jackterwilliger.com/biological-neural-networks-part-i-spiking-neurons/). For the purposes herein, you are interested in the activity of integrate and fire neurons.\n",
        "- [Wulfram Gerstner explains the dynamics of integrate and fire neurons](https://youtu.be/KGxVwJJC9zs?si=prIKnJAUBg5QNVYi).\n",
        "- [Learn more about the Nengo simulator here](https://www.nengo.ai/nengo/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVuGLdPrRoKZ"
      },
      "source": [
        "## Glossary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKF3u-KkRpzD"
      },
      "source": [
        "- **Input space**: the set of possible values that input can take. For example, the input space of a single photo receptor is the possible luminance values that the photosensor receives.\n",
        "- **Sensitivity**: the sensitivity of a (typically sensory) neuron measures the modulation of the neuron to some input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyB5_LH9mLRD"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7StXGltumPUl"
      },
      "source": [
        "In the cells below we install the nengo simulator and import relevant python packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTJu3u9Bi83"
      },
      "source": [
        "# Install Nengo into the colab via pip\n",
        "!pip install nengo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-729YdSaL15N"
      },
      "source": [
        "import nengo # our simulator\n",
        "import pandas as pd # to collect and handle data frames\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "import numpy as np # for numerical / mathematical functions\n",
        "import seaborn as sns # for nice plotting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PvuEPNpMnZm"
      },
      "source": [
        "from nengo.dists import Uniform # a nice uniform distribution\n",
        "from nengo.processes import WhiteSignal # a noise source\n",
        "from nengo.utils.ensemble import tuning_curves # tuning curves\n",
        "# from nengo.utils.ipython import hide_input\n",
        "from nengo.utils.matplotlib import rasterplot # for a convenient way of displaying raster plots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijmVPY0phMKd"
      },
      "source": [
        "# to add the plots directly to the jupyter document:\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qVZv-CShCwy"
      },
      "source": [
        "from nengo.dists import Uniform # a nice uniform distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_uyZYPcL0B1"
      },
      "source": [
        "# Modeling Population Encoding in Nengo\n",
        "\n",
        "A recipe for a model in Nengo is as follows:\n",
        "\n",
        "1. Create a model with `nengo.Network()` object.\n",
        "2. Create and insert inputs in the model via `nengo.Node()`.\n",
        "3. Add a number of neuronal populations via `nengo.Ensembles()`. Here we can also set the properties of our neurons, such as membrane time constant.\n",
        "4. Connect those ensembles via synapses via `nengo.Connection()`. Here we can also define synaptic properties. It is here as well, that we may want to define the **decoding functions**.\n",
        "5. Add some **probes** to the model with `nengo.Probe()` to record variables.\n",
        "6. Add the model to a `nengo.Simulator()` object and run.\n",
        "7. Plot selected variables using your package of choice (e.g., seaborn, matplotlib).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2UeQJ8x4FUm"
      },
      "source": [
        "## 1. Create a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTzcd1ANQJIm"
      },
      "source": [
        "This is the **object** that we will populate with inputs, neurons and probes, and that we will simulate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngEoCu5e4JoI"
      },
      "source": [
        "model = nengo.Network(label='NPH and VN') # Label is simply a name (string).\n",
        "\n",
        "# NPH : nucleus prepositus hippoglossi\n",
        "# VN  : vestibular nucleus\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKzzCeJU2-q1"
      },
      "source": [
        "## 2. Create an input:\n",
        "\n",
        "Nengo's function `Node()` is used to create inputs to networks. [Lambda notation](https://realpython.com/python-lambda/) is often used for the purpose.\n",
        "\n",
        "\n",
        "\n",
        "- for example, a function that returns a ramping input:\n",
        "\n",
        "$$ input(t) = t*2-1 $$\n",
        "\n",
        "is written in nengo as:\n",
        "\n",
        "> `input = nengo.Node(lambda t: t * 2 - 1)`\n",
        "\n",
        "- a function that returns 1 during a certain interval.\n",
        "\n",
        "> `input = nengo.Node(lambda t: 1 0] if t < 0.1 else 0)`\n",
        "\n",
        "- a function that produces a sine wave with a certain frequency\n",
        "\n",
        "> `input = nengo.Node(lambda t: sin(2*pi*t)`\n",
        "\n",
        "- combine the two last statements\n",
        "\n",
        "`input = nengo.Node(lambda t: sin(2*pi*t) if t > 1 else 0)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsNnM09a319N"
      },
      "source": [
        "with model: # to add things to model, we use 'with'\n",
        "  input = nengo.Node(lambda t: np.sin(2*1*np.pi * t)) # the input\n",
        "\n",
        "  # you cal also try other functions as input.\n",
        "  # input = nengo.Node(lambda t: t * 2 - 1)\n",
        "\n",
        "\n",
        "  input_probe = nengo.Probe(input) # with Probe we record a variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd_0KA-jJ5GF"
      },
      "source": [
        "In order to display our input, we need to run the model (this populates the output variables). We do that by adding our model to `Simulator()` on `model`  and running for `t` seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF01dZhjKlBZ"
      },
      "source": [
        "with nengo.Simulator(model) as sim:\n",
        "    sim.run(1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxqhGGn5QlJ2"
      },
      "source": [
        "Our model only has an input so far, no neurons. But we can plot it for sanity checking:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBAJjSITQxAp"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(sim.trange(), sim.data[input_probe], lw=2) #note 'input_probe' is what we created above. lw is line width.\n",
        "plt.title(\"Input signal\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.xlim(0, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LGYND-omihN"
      },
      "source": [
        "## 3. Create some Neurons that Cover the Input Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ev_QBamu7K"
      },
      "source": [
        "We will add an ensemble that encodes a continuous variable (representing some physical input to sensory neurons such as pressure, or light intensity). We do this by creating a set of neurons. Each of these neurons has a different tuning curve, such that together the neurons 'cover' the entire 'input space'. These tuning curves will have a mostly-linear relationship with an encoded quantity. In NENGO we refer to neurons with tuning curves as  'encoders'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKioogaWeQYl"
      },
      "source": [
        "---\n",
        "\n",
        "Firing characteristics of the Nucleus Prepositus Hipoglossi and Medial Vestibular Nucleus\n",
        "\n",
        "**System Specification:**\n",
        ">\n",
        "- Encode for horizontal eye position --\n",
        "  - Humans: 50deg horizontal eye motion (Davson 1990, p.657).\n",
        "  - In the model we can transform [-25 to 25] to a range between [-1, 1], without loss of generality!\n",
        "- Average background firing rates in the NPH: 0-150 Hz (Moschovakis 1997)\n",
        "- Maximum firing rate ~ 300Hz\n",
        "- Tuning curve sensitivities (mostly linear!) : 0.1 to 7 Hz / deg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw_m7d1y0HDA"
      },
      "source": [
        "### Tuning curves as basis functions\n",
        "We distribute the encoder neurons over the input space by setting neurons with intercepts along the encoded dimension, in this case from [-1 to 1]. We do this with a helper function `aligned()`, which we define below. We will use the output of this function to parameterize our encoding neurons to cover the base space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE6wWo-MlE_o"
      },
      "source": [
        "Example: Write a fuction called 'aligned', that returns two lists of N values, where:\n",
        "- **intercepts**: the value at which the neuron starts firing. Equally spaced points in an interval between [-radius, radius], where radius represents the possible values of an input around zero.\n",
        "- **encoders**: the slope of the tuning curves of the neuron. Here we simply use a vector populated with equal numbers of -1 (off neurons) and 1 (on neurons). The reasons for this choice are explained in Neuroengineering chapter 4).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwncuJXQlGwm"
      },
      "source": [
        "def aligned(n_neurons, radius=0.9):\n",
        "    intercepts = np.linspace(-radius, radius, n_neurons)\n",
        "    encoders = np.tile([[1], [-1]], (n_neurons // 2, 1))\n",
        "    intercepts *= encoders[:, 0]\n",
        "    return intercepts, encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsMxGZY1VaiX"
      },
      "source": [
        "#### Warm-up Exercise:\n",
        "**Call the function** defined above with 8 neurons and a radius of 1 and **inspect the output**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_WrBywd0g5t"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzq0Bjy8jR5v"
      },
      "source": [
        "### Check your answer below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VWJWJaBjF-I"
      },
      "source": [
        "intercepts, encoders = aligned(8, 1)\n",
        "print(intercepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_StMume2vBs"
      },
      "source": [
        "### Make an IF population of encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9agO0IeW2Zr"
      },
      "source": [
        "Below we create an ensemble of 8 IF neurons to encode the 1-dimensional input (e.g., the eye position) according to specified intercepts, encoders and with specified max_rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxmeVn9tMZT0"
      },
      "source": [
        "with model:\n",
        "    NPH = nengo.Ensemble( #NPH stands for 'nucleus prepositus hipoglossi'\n",
        "        8, # number of neurons in the ensemble\n",
        "        dimensions=1, # encoded stimulus dimensions (\"capacity\")\n",
        "        intercepts=intercepts,\n",
        "        max_rates=Uniform(80, 100), # the maximum firing rate of the neurons are drawn from the uniform distribution\n",
        "        encoders=encoders,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gksKPQ7tZEX1"
      },
      "source": [
        "We can plot the tuning curves of our neurons, with the function `tuning_curves` for population (In this case NPH)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scUex73aNE7D"
      },
      "source": [
        "with nengo.Simulator(model) as sim:\n",
        "    eval_points, activities = tuning_curves(NPH, sim)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(eval_points, activities, lw=2)\n",
        "plt.xlabel(\"Input signal\")\n",
        "plt.ylabel(\"Firing rate (Hz)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(tuning_curves)"
      ],
      "metadata": {
        "id": "k3yg4a1N2eLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8idrCw6DalS-"
      },
      "source": [
        "### 5. Connect the Inputs with Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NJ_h45GbRC5"
      },
      "source": [
        "We distribute the input to all neurons in the ensemble via `nengo.Connection()`. By default we connect the input to all postsynaptic neurons with equal weights*. Let's also create a probe for the spikes the model is producing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKceg-3hauyb"
      },
      "source": [
        "with model:\n",
        "    nengo.Connection(input, NPH)\n",
        "    NPH_spikes = nengo.Probe(NPH.neurons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXqcZzvocZvh"
      },
      "source": [
        "### 5. Run the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRP6GoRqdRdf"
      },
      "source": [
        "with nengo.Simulator(model) as sim:\n",
        "    sim.run(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlrBEXVaZpHb"
      },
      "source": [
        "## 6. How does the activity of the neurons look like??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Ai_KnUZxud"
      },
      "source": [
        "Now that we have the encoding neurons, the input and the probes, we can run the simulation and check the firing behavior of the neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK7BemRYfhgA"
      },
      "source": [
        "#### Raster Plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRG_uOr6aVxw"
      },
      "source": [
        "plt.figure(figsize=[15,4])\n",
        "ax = plt.subplot(1, 1, 1)\n",
        "rasterplot(sim.trange(), sim.data[NPH_spikes], ax)\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylabel(\"Neuron\")\n",
        "ax.set_xlabel(\"Time (s)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95aObpffjvv"
      },
      "source": [
        "#### Membrane Potential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhtB9wvKfmYs"
      },
      "source": [
        "with model:\n",
        "  nengo.Connection(input, NPH)\n",
        "  NPH_spikes = nengo.Probe(NPH.neurons, synapse=0.05)\n",
        "\n",
        "with nengo.Simulator(model) as sim:\n",
        "    sim.run(1)\n",
        "\n",
        "scale = 180\n",
        "plt.figure()\n",
        "for i in range(NPH.n_neurons):\n",
        "    plt.plot(sim.trange(), sim.data[NPH_spikes][:, i] - i * scale)\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(scale * (-NPH.n_neurons + 1), scale)\n",
        "plt.ylabel(\"Neuron\");\n",
        "plt.yticks(\n",
        "    np.arange(scale / 1.8, (-NPH.n_neurons + 1) * scale, -scale), np.arange(NPH.n_neurons)\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFu_x_KNd6qt"
      },
      "source": [
        "## 7. Check your decoding skills!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxrXbJWWeDYj"
      },
      "source": [
        "Can we decode those spikes and obtain our signal back? A decoder that produces the identity function can be obtained via a simple Probe. To find the decoding weights, the probe of a population uses the encoded value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8M9e3lhRniD"
      },
      "source": [
        "with model:\n",
        "    NPH_probe = nengo.Probe(NPH, synapse=0.2)\n",
        "    # 5ms PSC filter (AMPA like)\n",
        "    # 10ms PSC filter (GABA like)\n",
        "    # 100ms PSC filter (NMDA like)\n",
        "\n",
        "simtime = 5 #seconds\n",
        "\n",
        "with nengo.Simulator(model) as sim:\n",
        "    sim.run(simtime)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(sim.trange(), sim.data[NPH_probe], label=\"Decoded estimate\")\n",
        "plt.plot(sim.trange(), sim.data[input_probe], label=\"Input signal\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlim(0, simtime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH3bpl0gm2zk"
      },
      "source": [
        "# Questions and Exercises"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7d9ewb5IkS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5okN1gcm4wE"
      },
      "source": [
        "**1.(Question)** What significant assumption have we made about the distribution of tuning curves (hint: what is particular about our chosen intercepts / encoders)?\n",
        "\n",
        "**2. (Exercise).** Our network is rather small. Increase the number of neurons and observe the impact on decoding quality.\n",
        "\n",
        "**3. (Check).** Verify that the parameters of our network are specified according to the experimental data. Particularly, make sure that the values for individual neuronal tuning curves in the code above are specified as in the system parameters (section 3).\n",
        "\n",
        "**4. (Experiment)** Is the decoding quality a function of the input oscillation? In other words, does the network encode all frequencies equally well? Change the frequency of the sinusoidal input function and inspect the decoding quality. Are all possible input frequencies decoded equally well? Is there a dependency between quality of decoding and synapse time constant (determined in line 2 in the code block above).\n",
        "\n",
        "**5. (Challenge).** Create an 'efference copy' from the encoding population. That is: produce another population downstream from the encoding population that conveys the same 'quantity' (same number of dimensions). Now decode the original value from the second population. Try to spot the main differences in the activity of the two populations. Note: this exercise needs you to code a new Model, with an extra 'ensemble'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6ZjeZZb1ACV"
      },
      "source": [
        "# Bonus: Influence of Membrane Time Constant on Signal Reconstruction\n",
        "\n",
        "Code gracefully scraped from: https://github.com/ctn-waterloo/modelling_ideas/issues/91"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J81DQPa1JaD"
      },
      "source": [
        "def go(freq, tau_rc, n_neurons=10, tau_probe=0.005, t=1.0, dt=0.001, seed=0):\n",
        "    with nengo.Network() as model:\n",
        "        u = nengo.Node(output=lambda t: np.sin(2*np.pi*freq*t))\n",
        "        x = nengo.Ensemble(n_neurons, 1, seed=seed,\n",
        "                           neuron_type=nengo.LIF(tau_rc=tau_rc))\n",
        "        nengo.Connection(u, x, synapse=None)\n",
        "\n",
        "        p_u = nengo.Probe(u, synapse=tau_probe)\n",
        "        p_x = nengo.Probe(x, synapse=tau_probe)\n",
        "\n",
        "    with nengo.Simulator(model, dt=dt, progress_bar=False) as sim:\n",
        "        sim.run(t, progress_bar=False)\n",
        "\n",
        "    return nengo.utils.numpy.rmse(sim.data[p_u], sim.data[p_x])\n",
        "\n",
        "data = []\n",
        "for seed in range(5):\n",
        "    for freq in np.linspace(0, 50, 20):\n",
        "        for tau_rc in [0.001, 0.005, 0.01, 0.02, 0.1]:\n",
        "            print(freq, tau_rc)\n",
        "            data.append((freq, tau_rc, seed, go(freq, tau_rc, seed=seed)))\n",
        "df = pd.DataFrame(data, columns=(\"Frequency\", \"tau_rc\", \"Seed\", \"RMSE\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktc1f6Xm1bQM"
      },
      "source": [
        "plt.figure(figsize=[20,20])\n",
        "for tau_rc in df.tau_rc.unique():\n",
        "    sns.regplot(data=df[df['tau_rc'] == tau_rc], x_jitter=1.5,\n",
        "                x=\"Frequency\", y=\"RMSE\", label=str(tau_rc))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Encoding a two dimensional vector"
      ],
      "metadata": {
        "id": "vpK0cHMI4FcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the envirnment\n",
        "import numpy as np\n",
        "import nengo\n",
        "from nengo.dists import Uniform\n",
        "\n",
        "model = nengo.Network(label='2D Representation')\n",
        "with model:\n",
        "    #Two represent possible two dimensional input values, we choose sin and cos\n",
        "    sin = nengo.Node(output=np.sin)\n",
        "    cos = nengo.Node(output=np.cos)\n",
        "\n",
        "    # Create here an ensemble with 100 LIF neurons which represents a 2-dimensional signal\n",
        "    x = nengo.Ensemble(100, dimensions=2, max_rates=Uniform(100, 200))\n",
        "\n",
        "    #Get the neuron encoders\n",
        "    encoders = x.encoders.sample(100,2)\n",
        "\n",
        "    # Connecnting input to ensemble\n",
        "    # The indices in ensemble 'x' define which dimension the input will project to\n",
        "    nengo.Connection(sin, x[0])\n",
        "    nengo.Connection(cos, x[1])\n",
        "\n",
        "\n",
        "#place a probe to record a selected variable\n",
        "# Q: what changes with different synaptic time constants?\n",
        "with model:\n",
        "    probe1 = nengo.Probe(x.neurons, synapse=0.01)\n",
        "\n",
        "simtime = 5 #seconds\n",
        "# run the simulator for five seconds\n",
        "with nengo.Simulator(model) as sim:\n",
        "    sim.run(simtime)\n",
        "\n",
        "\n",
        "# plot the decoded 2D variables\n",
        "plt.figure()\n",
        "plt.plot(sim.trange(), sim.data[probe1], label=\"Decoded estimate\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlim(0, simtime)\n",
        "\n",
        "# challenge: can you plot the input signal as well?"
      ],
      "metadata": {
        "id": "cmEzn3LN3_Oz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}